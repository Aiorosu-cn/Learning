[TOC]

通过深度和法线信息,还可以做到更好的边缘检测,还能实现特定的处理效果

# 生成深度纹理值

深度和法线纹理,是经过变换后最后NDC投影空间里的深度和法线,不是外进传进来的法线纹理,基本思想就是把深度值和法线值转换为对应的颜色,然后绘制出来

特别是深度纹理,是一个0-1的值,因为颜色是一个0到1**的正数**,深度纹理值的来源是:
$$
d = 0.5\cdot Z_{ndc} + 0.5
\\
d:深度纹理中的颜色的值
\\
Z_{ndc}:NDC空间中的Z值
$$
如果选择生成一张深度 + 法线纹理,Unity会创建一张和屏幕分辨率相同,32位的纹理,其中R/G是法线信息,B/A是深度信息

# 采样深度纹理值

#### 在摄像机的脚本中设置获取深度纹理

```c#
camera.depthTextureMode = DepthTextureMode.Depth;
//或者
camera.depthTextureMode = DepthTextureMode.DepthNormals;
//或者同时生成2张纹理,深度和深度法线
camera.depthTextureMode |= DepthTextureMode.Depth;
camera.depthTextureMode |= DepthTextureMode.DepthNormals;
```





#### 在shader中直接访问纹理属性

设置好摄像机模式后,就可以直接在shader中声明变量访问

```glsl
float d = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, i.uv);
```

此时,我们获取的深度值是非线性的经过矩阵变换的,还需要倒推到真实的纹理值

# 从深度纹理中获取真实深度值(解码)
## 只采样深度值

unity提供了2个辅助函数,可以把通过采样得到的深度值还原为摄像机空间或者01线性空间

```glsl
LinearEyeDepth;//返回真实深度值
Linear01Depth;//返回01之间的线性深度值
```

## 同时采样深度和法线值

使用函数获取深度和法线纹理的值

```c#
tex2D(_CameraDepthTexture);
```

使用函数对采样结果解码,结果get 是一个线性空间

```c#
DecodeDepthNormal(float4 get, float depth, float3 normal);
//或者,想要分别获取
DecodeFloatRG();//深度
DecodeViewNormalStereo();//法线
```



生成的纹理存储在下面这个变量内

```glsl
_CameraDepthNormalsexture
```

然后我们使用函数对这个变量进行采样

```glsl
inline void DecodeDepthNormal()
```
# 基于深度的动态模糊

之前通过混合多张屏幕模拟运动模糊

现在使用速度映射图,通过计算像素的速度来决定模糊的方向和大小

思路:

记忆一个上一次世界到投影的变换矩阵

我们需要3个东西:

- 当前世界到投影的矩阵
- 当前世界到投影的逆矩阵
- 上一次世界到投影的矩阵

通过这3个可以计算每个点的运动程度

```c#
using UnityEngine;
using System.Collections;

public class MotionBlurWithDepthTexture : PostEffectsBase {

	public Shader motionBlurShader;
	private Material motionBlurMaterial = null;

	public Material material {  
		get {
			motionBlurMaterial = CheckShaderAndCreateMaterial(motionBlurShader, motionBlurMaterial);
			return motionBlurMaterial;
		}  
	}

	private Camera myCamera;
	public Camera camera {
		get {
			if (myCamera == null) {
				myCamera = GetComponent<Camera>();
			}
			return myCamera;
		}
	}

	[Range(0.0f, 1.0f)]
	public float blurSize = 0.5f;

    //上一次的世界到投影变换矩阵
	private Matrix4x4 previousViewProjectionMatrix;
	
	void OnEnable() {
        //使用深度纹理
		camera.depthTextureMode |= DepthTextureMode.Depth;

        //OpenGL的矩阵和向量运算规则使用的是列向量矩阵计算规则
        //DX的矩阵和向量运算规则使用的是行向量矩阵计算规则

        //举例：如果是一个物体经过 旋转、缩放、平移变换那么
        //DX中 ： 行向量 * 旋转矩阵*缩放矩阵*平移矩阵
        //GL中 ： 平移矩阵*缩放矩阵*旋转矩阵 * 列向量

        //将投影矩阵和世界到摄像机矩阵相乘得到的是前一次的世界到投影的矩阵
        previousViewProjectionMatrix = 
            camera.projectionMatrix * camera.worldToCameraMatrix;
	}
	
	void OnRenderImage (RenderTexture src, RenderTexture dest) {
		if (material != null) {
			material.SetFloat("_BlurSize", blurSize);

            //将前一次世界到投影的矩阵传入shader
			material.SetMatrix("_PreviousViewProjectionMatrix", previousViewProjectionMatrix);

            //当前世界到投影的矩阵（摄像*投影）
			Matrix4x4 currentViewProjectionMatrix = camera.projectionMatrix * camera.worldToCameraMatrix;
            //当前世界到投影的逆矩阵
            Matrix4x4 currentViewProjectionInverseMatrix = currentViewProjectionMatrix.inverse;
            //将当前世界到投影的逆矩阵传入shader
            material.SetMatrix("_CurrentViewProjectionInverseMatrix", currentViewProjectionInverseMatrix);
            //记录当前世界到投影的矩阵为前一次矩阵
            previousViewProjectionMatrix = currentViewProjectionMatrix;

			Graphics.Blit (src, dest, material);
		} else {
			Graphics.Blit(src, dest);
		}
	}
}
```

shader

```glsl
// Upgrade NOTE: replaced 'mul(UNITY_MATRIX_MVP,*)' with 'UnityObjectToClipPos(*)'

Shader "Unity Shaders Book/Chapter 13/Motion Blur With Depth Texture" {
	Properties {
		//使用了后期处理，必须有一个_MainTex
		_MainTex ("Base (RGB)", 2D) = "white" {}
		_BlurSize ("Blur Size", Float) = 1.0
	}
	SubShader {
		CGINCLUDE
		
		#include "UnityCG.cginc"
		
		sampler2D _MainTex;
		half4 _MainTex_TexelSize;//像素密度

		//在摄像机脚本中设置camera.depthTextureMode |= DepthTextureMode.Depth;
		//使用了深度纹理，需要使用_CameraDepthTexture这个变量
		sampler2D _CameraDepthTexture;//深度纹理内部自带
		//当前世界到投影的逆矩阵
		float4x4 _CurrentViewProjectionInverseMatrix;
		//前一次世界到投影的矩阵
		float4x4 _PreviousViewProjectionMatrix;
		//对应的模糊程度变量
		half _BlurSize;
		
		struct v2f {
			float4 pos : SV_POSITION;
			half2 uv : TEXCOORD0;
			half2 uv_depth : TEXCOORD1;
		};
		
		v2f vert(appdata_img v) {
			v2f o;
			o.pos = UnityObjectToClipPos(v.vertex);
			
			//深度和贴图使用的是相同的纹理UV
			o.uv = v.texcoord;
			o.uv_depth = v.texcoord;
			
			//如果深度纹理的UV坐标超出边界那么我们手动设置其为循环的方式
			//平台差异化的处理
			#if UNITY_UV_STARTS_AT_TOP
			if (_MainTex_TexelSize.y < 0)
				o.uv_depth.y = 1 - o.uv_depth.y;
			#endif
					 
			return o;
		}
		
		/*
		从深度纹理获取深度值与投影后的xy值组合还原为投影后的三维坐标。
		将这个坐标乘以世界到投影的逆矩阵，得到本次绘制当前点的世界位置。
		将这个世界位置通过上一次的世界到投影矩阵得到当前点上一次投影后的坐标位置。
		将本次的投影位置和上一次的投影位置相减当做移动速度或者说模糊程度。
		*/
		fixed4 frag(v2f i) : SV_Target {
			//从深度纹理获取深度值
			float d = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, i.uv_depth);
			//d获取到的范围是0-1 d = zdepth*0.5+0.5;
			// H is the viewport position at this pixel in the range -1 to 1.
			//投影以后的位置（裁剪空间的位置）
			float4 H = float4(i.uv.x * 2 - 1, i.uv.y * 2 - 1, d * 2 - 1, 1);
			// Transform by the view-projection inverse.
			//逆矩阵还原到世界中
			float4 D = mul(_CurrentViewProjectionInverseMatrix, H);
			// Divide by w to get the world position. 
			//齐次变换得到世界中的位置
			float4 worldPos = D / D.w;
			
			// Current viewport position 
			//本次投影的位置
			float4 currentPos = H;
			// Use the world position, and transform by the previous view-projection matrix. 
			//通过本次的世界坐标乘以前一次的变换矩阵
			//得到一个理论上前一次的投影后的位置 
			float4 previousPos = mul(_PreviousViewProjectionMatrix, worldPos);
			// Convert to nonhomogeneous points [-1,1] by dividing by w.
			previousPos /= previousPos.w;
			
			// Use this frame's position and last frame's to compute the pixel velocity.
			//将xy组合成二维向量计算两次投影后水平方向速度变化量
			float2 velocity = (currentPos.xy - previousPos.xy)/2.0f;
			
			float2 uv = i.uv;
			float4 c = tex2D(_MainTex, uv);
			uv += velocity * _BlurSize;
			for (int it = 1; it < 3; it++, uv += velocity * _BlurSize) {
				float4 currentColor = tex2D(_MainTex, uv);
				c += currentColor;
			}
			c /= 3;
			
			return fixed4(c.rgb, 1.0);
		}
		
		ENDCG
		
		Pass {      
			ZTest Always Cull Off ZWrite Off
			    	
			CGPROGRAM  
			
			#pragma vertex vert  
			#pragma fragment frag  
			  
			ENDCG  
		}
	} 
	FallBack Off
}
```
# 基于深度的雾化效果

有了深度值,可以实现深度雾的效果,即离摄像头多远,使用雾,在多近范围内没有雾

并且可以通过摄像机的脚本(脚本里包含了shader)





# 描边效果

找到法线和深度突变的地方

突变需要设置一个门槛

